"""æµ‹è¯•åˆ†æAPI - AIé©±åŠ¨çš„æµ‹è¯•æŠ¥å‘Šæ±‡æ€»åˆ†æ"""
from typing import Dict, Any, Optional
from fastapi import APIRouter, Depends, HTTPException, Request
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from sqlalchemy import func, and_
from datetime import datetime, timedelta
import httpx
import logging
import json
import ast

from app.db.session import get_db
from app.models.project import TestRun, TestCase, Project

logger = logging.getLogger(__name__)
router = APIRouter()

AI_ENGINE_URL = "http://localhost:8001"


@router.get("/test-runs/analyze-summary-stream")
async def analyze_test_summary_stream(
    request: Request,
    days: int = 30,
    project_id: Optional[int] = None,
    db: Session = Depends(get_db)
):
    """
    AIåˆ†ææµ‹è¯•æŠ¥å‘Šæ±‡æ€»ï¼ˆæµå¼è¾“å‡ºï¼‰
    """
    async def generate():
        try:
            # 1. æ”¶é›†æµ‹è¯•æ•°æ®
            cutoff_date = datetime.utcnow() - timedelta(days=days)
            
            query = db.query(TestRun)
            if project_id:
                query = query.filter(TestRun.project_id == project_id)
            query = query.filter(TestRun.created_at >= cutoff_date)
            
            test_runs = query.order_by(TestRun.id.desc()).all()
            
            if not test_runs:
                yield f"data: {json.dumps({'type': 'error', 'message': 'æš‚æ— æµ‹è¯•è¿è¡Œæ•°æ®'}, ensure_ascii=False)}\n\n"
                return
            
            # 2. æ„å»ºæ±‡æ€»æ•°æ®
            summary_data = {
                "total_runs": len(test_runs),
                "statistics": {
                    "total_cases": 0,
                    "passed_cases": 0,
                    "failed_cases": 0,
                    "skipped_cases": 0,
                    "error_cases": 0,
                },
                "overall_pass_rate": 0.0,
            }
            
            for tr in test_runs:
                if tr.results and isinstance(tr.results, dict):
                    total = tr.results.get("total_cases", 0) or 0
                    passed = tr.results.get("passed_cases", 0) or 0
                    failed = tr.results.get("failed_cases", 0) or 0
                    skipped = tr.results.get("skipped_cases", 0) or 0
                    error = tr.results.get("error_cases", 0) or 0
                    
                    summary_data["statistics"]["total_cases"] += total
                    summary_data["statistics"]["passed_cases"] += passed
                    summary_data["statistics"]["failed_cases"] += failed
                    summary_data["statistics"]["skipped_cases"] += skipped
                    summary_data["statistics"]["error_cases"] += error
            
            total = summary_data["statistics"]["total_cases"]
            passed = summary_data["statistics"]["passed_cases"]
            overall_pass_rate = (passed / total * 100) if total > 0 else 0
            summary_data["overall_pass_rate"] = round(overall_pass_rate, 2)
            
            # å‘é€åˆå§‹æ•°æ®
            yield f"data: {json.dumps({'type': 'summary', 'data': summary_data}, ensure_ascii=False)}\n\n"
            
            # 3. è°ƒç”¨AIå¼•æ“è¿›è¡Œæµå¼åˆ†æ
            try:
                async with httpx.AsyncClient() as client:
                    ai_prompt = f"""
è¯·åˆ†æä»¥ä¸‹æµ‹è¯•æ‰§è¡Œæ±‡æ€»æ•°æ®ï¼Œå¹¶æä¾›ä¸“ä¸šçš„æµ‹è¯•æ´å¯Ÿå’Œå»ºè®®ï¼š

## æµ‹è¯•æ‰§è¡Œæ¦‚å†µ
- åˆ†ææ—¶é—´æ®µï¼š{days}å¤©
- æµ‹è¯•è¿è¡Œæ€»æ•°ï¼š{summary_data['total_runs']}æ¬¡
- æ€»æµ‹è¯•ç”¨ä¾‹æ•°ï¼š{summary_data['statistics']['total_cases']}ä¸ª
- é€šè¿‡ç”¨ä¾‹ï¼š{summary_data['statistics']['passed_cases']}ä¸ª
- å¤±è´¥ç”¨ä¾‹ï¼š{summary_data['statistics']['failed_cases']}ä¸ª
- è·³è¿‡ç”¨ä¾‹ï¼š{summary_data['statistics']['skipped_cases']}ä¸ª
- é”™è¯¯ç”¨ä¾‹ï¼š{summary_data['statistics']['error_cases']}ä¸ª
- æ€»ä½“é€šè¿‡ç‡ï¼š{summary_data['overall_pass_rate']}%

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. **æ‰§è¡Œè¶‹åŠ¿åˆ†æ**ï¼šåˆ†ææµ‹è¯•æ‰§è¡Œçš„è¶‹åŠ¿å’Œæ¨¡å¼
2. **è´¨é‡è¯„ä¼°**ï¼šè¯„ä¼°æ•´ä½“æµ‹è¯•è´¨é‡ï¼ŒåŒ…æ‹¬é€šè¿‡ç‡ã€ç¨³å®šæ€§ç­‰
3. **é—®é¢˜è¯†åˆ«**ï¼šè¯†åˆ«å¸¸è§å¤±è´¥æ¨¡å¼ã€é«˜é£é™©åŒºåŸŸ
4. **æ”¹è¿›å»ºè®®**ï¼šæä¾›å…·ä½“çš„æµ‹è¯•ä¼˜åŒ–å»ºè®®
5. **é£é™©é¢„è­¦**ï¼šè¯†åˆ«æ½œåœ¨çš„è´¨é‡é£é™©ç‚¹

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…æ‹¬å…³é”®æŒ‡æ ‡ã€è¶‹åŠ¿ã€å»ºè®®ç­‰ã€‚
"""
                    
                    # ä½¿ç”¨æµå¼æ¥å£
                    async with client.stream(
                        "POST",
                        f"{AI_ENGINE_URL}/api/analyze-requirement-stream",
                        json={
                            "requirement_text": ai_prompt,
                            "project_context": f"æµ‹è¯•æ‰§è¡Œæ±‡æ€»åˆ†ææŠ¥å‘Š - åˆ†ææœ€è¿‘{days}å¤©çš„æµ‹è¯•æ•°æ®",
                            "test_focus": ["æµ‹è¯•è´¨é‡", "å¤±è´¥æ¨¡å¼", "æ”¹è¿›å»ºè®®"]
                        },
                        timeout=120.0
                    ) as response:
                        response.raise_for_status()
                        async for chunk_bytes in response.aiter_bytes():
                            if chunk_bytes:
                                chunk_text = chunk_bytes.decode('utf-8', errors='ignore')
                                # å¤„ç†SSEæ ¼å¼çš„æ•°æ®
                                for line in chunk_text.split('\n'):
                                    line = line.strip()
                                    if line.startswith('data: '):
                                        content = line[6:].strip()
                                        if content and content != '[DONE]':
                                            # å¦‚æœå†…å®¹å·²ç»æ˜¯JSONï¼Œå°è¯•è§£æ
                                            try:
                                                parsed = json.loads(content)
                                                if isinstance(parsed, dict) and 'content' in parsed:
                                                    yield f"data: {json.dumps({'type': 'chunk', 'content': parsed['content']}, ensure_ascii=False)}\n\n"
                                                else:
                                                    yield f"data: {json.dumps({'type': 'chunk', 'content': content}, ensure_ascii=False)}\n\n"
                                            except json.JSONDecodeError:
                                                # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬å†…å®¹
                                                yield f"data: {json.dumps({'type': 'chunk', 'content': content}, ensure_ascii=False)}\n\n"
                                    elif line and not line.startswith(':'):
                                        # éSSEæ ¼å¼çš„ç›´æ¥æ–‡æœ¬
                                        yield f"data: {json.dumps({'type': 'chunk', 'content': line}, ensure_ascii=False)}\n\n"
                
                yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
            except Exception as e:
                logger.error(f"AIæµå¼åˆ†æå¤±è´¥: {e}")
                yield f"data: {json.dumps({'type': 'error', 'message': f'AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}'}, ensure_ascii=False)}\n\n"
                
        except Exception as e:
            logger.error(f"æµå¼åˆ†æå¤±è´¥: {e}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")


@router.get("/test-runs/analyze-summary")
async def analyze_test_summary(
    days: int = 30,
    project_id: Optional[int] = None,
    db: Session = Depends(get_db)
):
    """
    AIåˆ†ææµ‹è¯•æŠ¥å‘Šæ±‡æ€»
    åˆ†ææœ€è¿‘Nå¤©çš„æµ‹è¯•è¿è¡Œæ•°æ®ï¼Œæä¾›AIé©±åŠ¨çš„æ´å¯Ÿå’Œå»ºè®®
    """
    try:
        # 1. æ”¶é›†æµ‹è¯•æ•°æ®
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        
        query = db.query(TestRun)
        if project_id:
            query = query.filter(TestRun.project_id == project_id)
        
        # TestRunç»§æ‰¿è‡ªBaseï¼ŒBaseæœ‰created_atå­—æ®µ
        # æŒ‰æ—¶é—´è¿‡æ»¤ï¼Œåªè·å–æœ€è¿‘Nå¤©çš„æ•°æ®
        query = query.filter(TestRun.created_at >= cutoff_date)
        
        test_runs = query.order_by(TestRun.id.desc()).all()
        
        if not test_runs:
            return {
                "summary": {
                    "total_runs": 0,
                    "date_range": {
                        "start": cutoff_date.isoformat(),
                        "end": datetime.utcnow().isoformat()
                    },
                    "statistics": {
                        "total_cases": 0,
                        "passed_cases": 0,
                        "failed_cases": 0,
                        "skipped_cases": 0,
                        "error_cases": 0,
                    },
                    "status_distribution": {
                        "completed": 0,
                        "failed": 0,
                        "running": 0,
                        "pending": 0,
                        "cancelled": 0
                    },
                    "overall_pass_rate": 0.0,
                    "test_runs": []
                },
                "analysis": "æš‚æ— æµ‹è¯•è¿è¡Œæ•°æ®ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚è¯·å…ˆæ‰§è¡Œä¸€äº›æµ‹è¯•è¿è¡Œã€‚",
                "key_metrics": {
                    "overall_pass_rate": 0.0,
                    "total_test_runs": 0,
                    "total_test_cases": 0,
                    "failure_rate": 0.0,
                    "avg_pass_rate": 0.0
                },
                "generated_at": datetime.utcnow().isoformat()
            }
        
        # 2. æ„å»ºæ±‡æ€»æ•°æ®
        summary_data = {
            "total_runs": len(test_runs),
            "date_range": {
                "start": cutoff_date.isoformat(),
                "end": datetime.utcnow().isoformat()
            },
            "statistics": {
                "total_cases": 0,
                "passed_cases": 0,
                "failed_cases": 0,
                "skipped_cases": 0,
                "error_cases": 0,
            },
            "status_distribution": {
                "completed": 0,
                "failed": 0,
                "running": 0,
                "pending": 0,
                "cancelled": 0
            },
            "test_runs": []
        }
        
        # 3. åˆ†ææ¯ä¸ªæµ‹è¯•è¿è¡Œ
        for tr in test_runs:
            # ç¡®ä¿resultsæ˜¯å­—å…¸ç±»å‹
            if not tr.results:
                tr.results = {}
            if isinstance(tr.results, dict):
                total = tr.results.get("total_cases", 0) or 0
                passed = tr.results.get("passed_cases", 0) or 0
                failed = tr.results.get("failed_cases", 0) or 0
                skipped = tr.results.get("skipped_cases", 0) or 0
                error = tr.results.get("error_cases", 0) or 0
                
                summary_data["statistics"]["total_cases"] += total
                summary_data["statistics"]["passed_cases"] += passed
                summary_data["statistics"]["failed_cases"] += failed
                summary_data["statistics"]["skipped_cases"] += skipped
                summary_data["statistics"]["error_cases"] += error
                
                # è®¡ç®—é€šè¿‡ç‡
                pass_rate = (passed / total * 100) if total > 0 else 0
                
                summary_data["test_runs"].append({
                    "id": tr.id,
                    "name": tr.name,
                    "status": tr.status,
                    "total_cases": total,
                    "passed_cases": passed,
                    "failed_cases": failed,
                    "skipped_cases": skipped,
                    "error_cases": error,
                    "pass_rate": round(pass_rate, 2),
                    "start_time": tr.start_time if tr.start_time else None,
                    "end_time": tr.end_time if tr.end_time else None,
                    "duration": tr.results.get("duration", 0)
                })
            
            # ç»Ÿè®¡çŠ¶æ€åˆ†å¸ƒ
            status = tr.status
            if status in summary_data["status_distribution"]:
                summary_data["status_distribution"][status] += 1
        
        # è®¡ç®—æ€»ä½“é€šè¿‡ç‡
        total = summary_data["statistics"]["total_cases"]
        passed = summary_data["statistics"]["passed_cases"]
        overall_pass_rate = (passed / total * 100) if total > 0 else 0
        summary_data["overall_pass_rate"] = round(overall_pass_rate, 2)
        
        # 4. è°ƒç”¨AIå¼•æ“è¿›è¡Œåˆ†æ
        try:
            async with httpx.AsyncClient() as client:
                ai_prompt = f"""
è¯·åˆ†æä»¥ä¸‹æµ‹è¯•æ‰§è¡Œæ±‡æ€»æ•°æ®ï¼Œå¹¶æä¾›ä¸“ä¸šçš„æµ‹è¯•æ´å¯Ÿå’Œå»ºè®®ï¼š

## æµ‹è¯•æ‰§è¡Œæ¦‚å†µ
- åˆ†ææ—¶é—´æ®µï¼š{days}å¤©
- æµ‹è¯•è¿è¡Œæ€»æ•°ï¼š{summary_data['total_runs']}æ¬¡
- æ€»æµ‹è¯•ç”¨ä¾‹æ•°ï¼š{summary_data['statistics']['total_cases']}ä¸ª
- é€šè¿‡ç”¨ä¾‹ï¼š{summary_data['statistics']['passed_cases']}ä¸ª
- å¤±è´¥ç”¨ä¾‹ï¼š{summary_data['statistics']['failed_cases']}ä¸ª
- è·³è¿‡ç”¨ä¾‹ï¼š{summary_data['statistics']['skipped_cases']}ä¸ª
- é”™è¯¯ç”¨ä¾‹ï¼š{summary_data['statistics']['error_cases']}ä¸ª
- æ€»ä½“é€šè¿‡ç‡ï¼š{summary_data['overall_pass_rate']}%

## æµ‹è¯•è¿è¡ŒçŠ¶æ€åˆ†å¸ƒ
- å·²å®Œæˆï¼š{summary_data['status_distribution']['completed']}æ¬¡
- å·²å¤±è´¥ï¼š{summary_data['status_distribution']['failed']}æ¬¡
- æ‰§è¡Œä¸­ï¼š{summary_data['status_distribution']['running']}æ¬¡
- å¾…æ‰§è¡Œï¼š{summary_data['status_distribution']['pending']}æ¬¡
- å·²å–æ¶ˆï¼š{summary_data['status_distribution']['cancelled']}æ¬¡

## è¯¦ç»†æµ‹è¯•è¿è¡Œæ•°æ®
{summary_data['test_runs'][:10]}  # åªå–å‰10ä¸ªä½œä¸ºæ ·æœ¬

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. **æ‰§è¡Œè¶‹åŠ¿åˆ†æ**ï¼šåˆ†ææµ‹è¯•æ‰§è¡Œçš„è¶‹åŠ¿å’Œæ¨¡å¼
2. **è´¨é‡è¯„ä¼°**ï¼šè¯„ä¼°æ•´ä½“æµ‹è¯•è´¨é‡ï¼ŒåŒ…æ‹¬é€šè¿‡ç‡ã€ç¨³å®šæ€§ç­‰
3. **é—®é¢˜è¯†åˆ«**ï¼šè¯†åˆ«å¸¸è§å¤±è´¥æ¨¡å¼ã€é«˜é£é™©åŒºåŸŸ
4. **æ”¹è¿›å»ºè®®**ï¼šæä¾›å…·ä½“çš„æµ‹è¯•ä¼˜åŒ–å»ºè®®
5. **é£é™©é¢„è­¦**ï¼šè¯†åˆ«æ½œåœ¨çš„è´¨é‡é£é™©ç‚¹

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…æ‹¬å…³é”®æŒ‡æ ‡ã€è¶‹åŠ¿ã€å»ºè®®ç­‰ã€‚
"""
                
                # ä½¿ç”¨éœ€æ±‚åˆ†æçš„ç«¯ç‚¹æ¨¡å¼ï¼Œä½†ä¼ é€’æµ‹è¯•åˆ†æprompt
                try:
                    response = await client.post(
                        f"{AI_ENGINE_URL}/analyze_requirement",
                        json={
                            "requirement_text": ai_prompt,
                            "project_context": f"æµ‹è¯•æ‰§è¡Œæ±‡æ€»åˆ†ææŠ¥å‘Š - åˆ†ææœ€è¿‘{days}å¤©çš„æµ‹è¯•æ•°æ®",
                            "test_focus": ["æµ‹è¯•è´¨é‡", "å¤±è´¥æ¨¡å¼", "æ”¹è¿›å»ºè®®"]
                        },
                        timeout=120.0
                    )
                    response.raise_for_status()
                    ai_result = response.json()
                    # æå–åˆ†æå†…å®¹ - AIå¼•æ“è¿”å›æ ¼å¼ä¸º {"status": "success", "analysis": {...}}
                    if isinstance(ai_result, dict):
                        analysis_data = ai_result.get("analysis", {})
                        
                        # å¦‚æœanalysis_dataæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºå­—å…¸
                        if isinstance(analysis_data, str):
                            try:
                                # å°è¯•ä½¿ç”¨ast.literal_evalè§£æPythonå­—å…¸å­—ç¬¦ä¸²ï¼ˆå®‰å…¨ï¼‰
                                analysis_data = ast.literal_eval(analysis_data)
                            except (ValueError, SyntaxError) as e:
                                logger.warning(f"ast.literal_evalè§£æå¤±è´¥: {e}")
                                try:
                                    # å¦‚æœast.literal_evalå¤±è´¥ï¼Œå°è¯•JSONè§£æï¼ˆéœ€è¦å°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·ï¼‰
                                    # æ³¨æ„ï¼šè¿™åªèƒ½å¤„ç†ç®€å•çš„JSONæ ¼å¼
                                    json_str = analysis_data.replace("'", '"')
                                    analysis_data = json.loads(json_str)
                                except (json.JSONDecodeError, AttributeError) as e:
                                    logger.warning(f"JSONè§£æä¹Ÿå¤±è´¥: {e}")
                                    # å¦‚æœéƒ½å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²
                                    ai_analysis = analysis_data
                                    analysis_data = None
                        
                        # å¦‚æœanalysis_dataæ˜¯å­—å…¸ï¼Œæ ¼å¼åŒ–
                        if analysis_data and isinstance(analysis_data, dict):
                            # å°†ç»“æ„åŒ–æ•°æ®è½¬æ¢ä¸ºMarkdownæ ¼å¼
                            ai_analysis = _format_analysis_as_markdown(analysis_data)
                        elif analysis_data:
                            ai_analysis = str(analysis_data) if analysis_data else "åˆ†æå®Œæˆï¼Œä½†æœªè¿”å›è¯¦ç»†å†…å®¹"
                        elif not isinstance(analysis_data, dict) and analysis_data is None:
                            # å¦‚æœè§£æå¤±è´¥ä½†æ²¡æœ‰è®¾ç½®ai_analysisï¼Œä½¿ç”¨é»˜è®¤å€¼
                            ai_analysis = "åˆ†æå®Œæˆï¼Œä½†æ— æ³•è§£æè¯¦ç»†å†…å®¹"
                    else:
                        ai_analysis = str(ai_result)
                except httpx.RequestError as e:
                    logger.error(f"AIå¼•æ“è¯·æ±‚å¤±è´¥: {e}")
                    ai_analysis = "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½†å·²æä¾›åŸºç¡€ç»Ÿè®¡æ•°æ®ã€‚"
                except httpx.HTTPStatusError as e:
                    logger.error(f"AIå¼•æ“å“åº”é”™è¯¯: {e.response.status_code} - {e.response.text}")
                    ai_analysis = "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½†å·²æä¾›åŸºç¡€ç»Ÿè®¡æ•°æ®ã€‚"
                
        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}", exc_info=True)
            ai_analysis = "AIåˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½†å·²æä¾›åŸºç¡€ç»Ÿè®¡æ•°æ®ã€‚"
        
        # 5. è¿”å›ç»“æœ
        return {
            "summary": summary_data,
            "analysis": ai_analysis,
            "key_metrics": {
                "overall_pass_rate": summary_data["overall_pass_rate"],
                "total_test_runs": summary_data["total_runs"],
                "total_test_cases": summary_data["statistics"]["total_cases"],
                "failure_rate": round((summary_data["statistics"]["failed_cases"] / total * 100) if total > 0 else 0, 2),
                "avg_pass_rate": _calculate_avg_pass_rate(summary_data["test_runs"])
            },
            "generated_at": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"åˆ†ææµ‹è¯•æ±‡æ€»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")


def _calculate_avg_pass_rate(test_runs: list) -> float:
    """è®¡ç®—å¹³å‡é€šè¿‡ç‡"""
    if not test_runs:
        return 0.0
    
    total_pass_rate = sum(run.get("pass_rate", 0) for run in test_runs)
    return round(total_pass_rate / len(test_runs), 2)


def _format_analysis_as_markdown(analysis_data: dict) -> str:
    """å°†AIåˆ†æç»“æœæ ¼å¼åŒ–ä¸ºMarkdownæ ¼å¼"""
    markdown_parts = []
    
    # 1. åŠŸèƒ½è¦ç‚¹åˆ†æ
    if "functional_points" in analysis_data and analysis_data["functional_points"]:
        markdown_parts.append("## ğŸ“‹ åŠŸèƒ½è¦ç‚¹åˆ†æ\n")
        func_points = analysis_data["functional_points"]
        if isinstance(func_points, list):
            for i, point in enumerate(func_points, 1):
                if isinstance(point, dict):
                    point_name = point.get("point", "")
                    priority = point.get("priority", "")
                    complexity = point.get("complexity", "")
                    risk_level = point.get("risk_level", "")
                    markdown_parts.append(f"{i}. **{point_name}**")
                    if priority:
                        markdown_parts.append(f"   - ä¼˜å…ˆçº§: {priority}")
                    if complexity:
                        markdown_parts.append(f"   - å¤æ‚åº¦: {complexity}")
                    if risk_level:
                        markdown_parts.append(f"   - é£é™©çº§åˆ«: {risk_level}")
                    markdown_parts.append("")
        markdown_parts.append("\n")
    
    # 2. æµ‹è¯•è¾¹ç•Œæ¡ä»¶
    if "test_boundaries" in analysis_data and analysis_data["test_boundaries"]:
        markdown_parts.append("## ğŸ”² æµ‹è¯•è¾¹ç•Œæ¡ä»¶\n")
        boundaries = analysis_data["test_boundaries"]
        if isinstance(boundaries, list):
            for i, boundary in enumerate(boundaries, 1):
                if isinstance(boundary, dict):
                    boundary_desc = boundary.get("boundary", "")
                    test_type = boundary.get("test_type", "")
                    priority = boundary.get("priority", "")
                    markdown_parts.append(f"{i}. **{boundary_desc}**")
                    if test_type:
                        markdown_parts.append(f"   - æµ‹è¯•ç±»å‹: {test_type}")
                    if priority:
                        markdown_parts.append(f"   - ä¼˜å…ˆçº§: {priority}")
                    markdown_parts.append("")
        markdown_parts.append("\n")
    
    # 3. æ½œåœ¨é£é™©ç‚¹
    if "risk_points" in analysis_data and analysis_data["risk_points"]:
        markdown_parts.append("## âš ï¸ æ½œåœ¨é£é™©ç‚¹\n")
        risks = analysis_data["risk_points"]
        if isinstance(risks, list):
            for i, risk in enumerate(risks, 1):
                if isinstance(risk, dict):
                    risk_desc = risk.get("risk", "")
                    impact = risk.get("impact", "")
                    mitigation = risk.get("mitigation", "")
                    markdown_parts.append(f"### é£é™© {i}: {risk_desc}\n")
                    if impact:
                        markdown_parts.append(f"- **å½±å“ç¨‹åº¦**: {impact}")
                    if mitigation:
                        markdown_parts.append(f"- **ç¼“è§£æªæ–½**: {mitigation}")
                    markdown_parts.append("")
        markdown_parts.append("\n")
    
    # 4. æµ‹è¯•ç­–ç•¥å»ºè®®
    if "test_strategy" in analysis_data and analysis_data["test_strategy"]:
        markdown_parts.append("## ğŸ¯ æµ‹è¯•ç­–ç•¥å»ºè®®\n")
        strategy = analysis_data["test_strategy"]
        if isinstance(strategy, dict):
            overall = strategy.get("overall_approach", "")
            if overall:
                markdown_parts.append(f"### æ•´ä½“ç­–ç•¥\n{overall}\n")
            
            test_levels = strategy.get("test_levels", [])
            if test_levels:
                markdown_parts.append(f"### æµ‹è¯•å±‚çº§\n- " + "\n- ".join(test_levels) + "\n")
            
            automation = strategy.get("automation_scope", "")
            if automation:
                markdown_parts.append(f"### è‡ªåŠ¨åŒ–èŒƒå›´\n{automation}\n")
            
            tools = strategy.get("tools_recommendation", [])
            if tools:
                markdown_parts.append(f"### æ¨èå·¥å…·\n- " + "\n- ".join(tools) + "\n")
        markdown_parts.append("\n")
    
    # 5. æµ‹è¯•ä¼˜å…ˆçº§
    if "test_priorities" in analysis_data and analysis_data["test_priorities"]:
        markdown_parts.append("## ğŸ“Š æµ‹è¯•ä¼˜å…ˆçº§\n")
        priorities = analysis_data["test_priorities"]
        if isinstance(priorities, list):
            for i, priority_item in enumerate(priorities, 1):
                if isinstance(priority_item, dict):
                    area = priority_item.get("area", "")
                    priority_level = priority_item.get("priority", "")
                    rationale = priority_item.get("rationale", "")
                    markdown_parts.append(f"{i}. **{area}** (ä¼˜å…ˆçº§: {priority_level})")
                    if rationale:
                        markdown_parts.append(f"   - ç†ç”±: {rationale}")
                    markdown_parts.append("")
        markdown_parts.append("\n")
    
    # 6. é¢„ä¼°å·¥ä½œé‡
    if "estimated_effort" in analysis_data and analysis_data["estimated_effort"]:
        markdown_parts.append("## â±ï¸ é¢„ä¼°å·¥ä½œé‡\n")
        effort = analysis_data["estimated_effort"]
        if isinstance(effort, dict):
            total = effort.get("total_hours", 0)
            if total:
                markdown_parts.append(f"**æ€»å·¥ä½œé‡**: {total} å°æ—¶\n")
            
            breakdown = effort.get("breakdown", {})
            if breakdown:
                markdown_parts.append("### å·¥ä½œé‡åˆ†è§£\n")
                for key, value in breakdown.items():
                    key_name_map = {
                        "test_planning": "æµ‹è¯•è§„åˆ’",
                        "test_design": "æµ‹è¯•è®¾è®¡",
                        "test_execution": "æµ‹è¯•æ‰§è¡Œ",
                        "automation": "è‡ªåŠ¨åŒ–"
                    }
                    key_display = key_name_map.get(key, key)
                    markdown_parts.append(f"- {key_display}: {value} å°æ—¶")
                markdown_parts.append("")
        markdown_parts.append("\n")
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æ„åŒ–æ•°æ®ï¼Œå°è¯•æå–å…¶ä»–å­—æ®µ
    if not markdown_parts:
        if "analysis" in analysis_data:
            ai_analysis = str(analysis_data.get("analysis", ""))
            return ai_analysis
        else:
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°†æ•´ä¸ªå¯¹è±¡æ ¼å¼åŒ–ä¸ºJSON
            return json.dumps(analysis_data, ensure_ascii=False, indent=2)
    
    return "\n".join(markdown_parts)

